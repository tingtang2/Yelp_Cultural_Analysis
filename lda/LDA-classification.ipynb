{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.load_npz('/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/X_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc= np.load(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentDirichletAllocation(n_components = 25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=25, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'lda.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = sparse.load_npz('/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/X_val.npz')\n",
    "X_test = sparse.load_npz('/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/X_test.npz')\n",
    "\n",
    "total_X = sparse.vstack([X_val, X_test])\n",
    "\n",
    "ix = total_X.getnnz(1)>0\n",
    "total_X = total_X[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.transform(total_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = model.transform(X_train)\n",
    "np.save(\"lda_transformed_train\", train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"lda_transformed_test\", transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transformed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(solver = 'liblinear', verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(train_transform, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda_reduced_trained_logit']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(logit, \"lda_reduced_trained_logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logit.predict(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"logit_predictions_lda_reduced\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_val= np.load(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_test= np.load(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_c = np.concatenate((cc_val, cc_test))\n",
    "total_c= total_c[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.00      0.00     31405\n",
      "           1       0.60      0.61      0.60    113782\n",
      "           2       0.21      0.05      0.08     25626\n",
      "           3       0.00      0.00      0.00      6474\n",
      "           4       0.49      0.54      0.52    141680\n",
      "           5       0.00      0.00      0.00     17033\n",
      "           6       0.00      0.00      0.00      8933\n",
      "           7       0.00      0.00      0.00      6293\n",
      "           8       0.00      0.00      0.00      9964\n",
      "           9       0.25      0.08      0.12     26425\n",
      "          10       0.32      0.60      0.42    271113\n",
      "          11       0.33      0.36      0.34     94169\n",
      "          12       0.31      0.00      0.00     11026\n",
      "          13       0.00      0.00      0.00      7135\n",
      "          14       0.46      0.48      0.47     27818\n",
      "          15       0.31      0.34      0.32    263881\n",
      "          16       0.20      0.02      0.04     35477\n",
      "          17       0.00      0.00      0.00      4755\n",
      "          18       0.72      0.66      0.69    149342\n",
      "          19       0.26      0.00      0.01     14345\n",
      "          20       0.48      0.46      0.47     48006\n",
      "          21       0.00      0.00      0.00     21871\n",
      "          22       0.00      0.00      0.00      7874\n",
      "          23       0.00      0.00      0.00      4856\n",
      "          24       0.46      0.33      0.38     32690\n",
      "          25       0.20      0.03      0.05     34972\n",
      "          26       0.00      0.00      0.00      5973\n",
      "          27       0.00      0.00      0.00      7781\n",
      "\n",
      "    accuracy                           0.41   1430699\n",
      "   macro avg       0.20      0.16      0.16   1430699\n",
      "weighted avg       0.37      0.41      0.37   1430699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(total_c, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c3rLDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitc3 = LogisticRegression(solver = 'liblinear', verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_ndz = np.load(\"c3rLDA_eval_ndz.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_ndz= (c3_ndz + .1).astype(float)\n",
    "c3_ndz /= np.sum(c3_ndz, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_train_ndz = np.load(\"./model_persistence/all_eths_less_than_15000_1000_its_25_topics/ndz.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_train_ndz= (c3_train_ndz + .1).astype(float)\n",
    "c3_train_ndz /= np.sum(c3_train_ndz, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = X_train.getnnz(1)>0\n",
    "cc= cc[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitc3.fit(c3_train_ndz, cc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_c3 = logitc3.predict(c3_ndz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.00      0.00     31405\n",
      "           1       0.20      0.13      0.16    113782\n",
      "           2       0.00      0.00      0.00     25626\n",
      "           3       0.00      0.00      0.00      6474\n",
      "           4       0.20      0.02      0.04    141680\n",
      "           5       0.00      0.00      0.00     17033\n",
      "           6       0.00      0.00      0.00      8933\n",
      "           7       0.00      0.00      0.00      6293\n",
      "           8       0.00      0.00      0.00      9964\n",
      "           9       0.00      0.00      0.00     26425\n",
      "          10       0.26      0.63      0.37    271113\n",
      "          11       0.25      0.43      0.31     94169\n",
      "          12       0.00      0.00      0.00     11026\n",
      "          13       0.00      0.00      0.00      7135\n",
      "          14       0.00      0.00      0.00     27818\n",
      "          15       0.25      0.37      0.30    263881\n",
      "          16       0.15      0.00      0.01     35477\n",
      "          17       0.00      0.00      0.00      4755\n",
      "          18       0.11      0.08      0.10    149342\n",
      "          19       0.00      0.00      0.00     14345\n",
      "          20       0.29      0.00      0.00     48006\n",
      "          21       0.00      0.00      0.00     21871\n",
      "          22       0.17      0.02      0.03      7874\n",
      "          23       0.00      0.00      0.00      4856\n",
      "          24       0.00      0.00      0.00     32690\n",
      "          25       0.16      0.02      0.04     34972\n",
      "          26       0.00      0.00      0.00      5973\n",
      "          27       0.00      0.00      0.00      7781\n",
      "\n",
      "    accuracy                           0.24   1430699\n",
      "   macro avg       0.08      0.06      0.05   1430699\n",
      "weighted avg       0.18      0.24      0.17   1430699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(total_c, predictions_c3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ccLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitcc = LogisticRegression(solver = 'liblinear', verbose= 1)\n",
    "cc_train_ndz = np.load(\"./cc_ndz.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train_ndz = (cc_train_ndz + .1).astype(float)\n",
    "cc_train_ndz /= np.sum(cc_train_ndz, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitcc.fit(cc_train_ndz, cc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_ndz = np.load(\"c3rLDA_eval_ndz.npy\")\n",
    "cc_ndz= (cc_ndz + .1).astype(float)\n",
    "cc_ndz /= np.sum(cc_ndz, axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "predictions_cc = logitcc.predict(cc_ndz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     31405\n",
      "           1       0.05      0.08      0.06    113782\n",
      "           2       0.00      0.00      0.00     25626\n",
      "           3       0.00      0.00      0.00      6474\n",
      "           4       0.06      0.00      0.00    141680\n",
      "           5       0.00      0.00      0.00     17033\n",
      "           6       0.00      0.00      0.00      8933\n",
      "           7       0.00      0.00      0.00      6293\n",
      "           8       0.00      0.00      0.00      9964\n",
      "           9       0.00      0.00      0.00     26425\n",
      "          10       0.16      0.33      0.22    271113\n",
      "          11       0.03      0.00      0.00     94169\n",
      "          12       0.00      0.00      0.00     11026\n",
      "          13       0.00      0.00      0.00      7135\n",
      "          14       0.00      0.00      0.00     27818\n",
      "          15       0.17      0.22      0.19    263881\n",
      "          16       0.00      0.00      0.00     35477\n",
      "          17       0.00      0.00      0.00      4755\n",
      "          18       0.07      0.16      0.10    149342\n",
      "          19       0.00      0.00      0.00     14345\n",
      "          20       0.00      0.00      0.00     48006\n",
      "          21       0.00      0.00      0.00     21871\n",
      "          22       0.00      0.00      0.00      7874\n",
      "          23       0.00      0.00      0.00      4856\n",
      "          24       0.00      0.00      0.00     32690\n",
      "          25       0.00      0.00      0.00     34972\n",
      "          26       0.00      0.00      0.00      5973\n",
      "          27       0.00      0.00      0.00      7781\n",
      "\n",
      "    accuracy                           0.13   1430699\n",
      "   macro avg       0.02      0.03      0.02   1430699\n",
      "weighted avg       0.08      0.13      0.09   1430699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(total_c, predictions_cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitno = LogisticRegression(solver = 'liblinear', verbose= 1)\n",
    "logitno.fit(X_train, cc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_no = logitno.predict(total_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.16      0.23     31405\n",
      "           1       0.71      0.70      0.71    113782\n",
      "           2       0.55      0.41      0.47     25626\n",
      "           3       0.82      0.51      0.63      6474\n",
      "           4       0.73      0.65      0.69    141680\n",
      "           5       0.59      0.35      0.44     17033\n",
      "           6       0.58      0.31      0.40      8933\n",
      "           7       0.22      0.03      0.06      6293\n",
      "           8       0.17      0.05      0.08      9964\n",
      "           9       0.60      0.38      0.46     26425\n",
      "          10       0.42      0.63      0.50    271113\n",
      "          11       0.63      0.58      0.60     94169\n",
      "          12       0.65      0.40      0.50     11026\n",
      "          13       0.66      0.29      0.41      7135\n",
      "          14       0.61      0.61      0.61     27818\n",
      "          15       0.41      0.47      0.44    263881\n",
      "          16       0.68      0.42      0.52     35477\n",
      "          17       0.12      0.03      0.05      4755\n",
      "          18       0.71      0.71      0.71    149342\n",
      "          19       0.63      0.35      0.45     14345\n",
      "          20       0.74      0.60      0.66     48006\n",
      "          21       0.21      0.04      0.07     21871\n",
      "          22       0.54      0.28      0.37      7874\n",
      "          23       0.62      0.38      0.47      4856\n",
      "          24       0.72      0.61      0.66     32690\n",
      "          25       0.60      0.38      0.47     34972\n",
      "          26       0.73      0.44      0.55      5973\n",
      "          27       0.63      0.29      0.40      7781\n",
      "\n",
      "    accuracy                           0.55   1430699\n",
      "   macro avg       0.56      0.40      0.45   1430699\n",
      "weighted avg       0.56      0.55      0.54   1430699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(total_c, predictions_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression on Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = []\n",
    "with open(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/locs_train.json\", 'r') as file:\n",
    "    locs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = np.array(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = X_train.getnnz(1)>0\n",
    "locs= np.array(locs)[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_reg.fit(train_transform, locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reg_pred = lda_reg.predict(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_val = []\n",
    "with open(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/locs_val.json\", 'r') as file:\n",
    "    locs_val = json.load(file)\n",
    "locs_test = []\n",
    "with open(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/locs_test.json\", 'r') as file:\n",
    "    locs_test = json.load(file)\n",
    "    \n",
    "total_locs = locs_val + locs_test\n",
    "total_locs= np.array(total_locs)[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "\n",
    "distance_errors = []\n",
    "\n",
    "for i in range(total_locs.shape[0]):\n",
    "    distance_errors.append(geopy.distance.distance(total_locs[i], lda_reg_pred[i]).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'geodesic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-16fd6216383e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'geodesic'"
     ]
    }
   ],
   "source": [
    "sum(distance_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1335.734786532042"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x.km for x in distance_errors])/len(distance_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression for c3rlda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3rlda_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = X_train.getnnz(1)>0\n",
    "locs = locs[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3rlda_reg.fit(c3_train_ndz, locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430699, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_locs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3rlda_reg_pred = c3rlda_reg.predict(c3_ndz)\n",
    "\n",
    "c3_distance_errors = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'geodesic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-fba54d144829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mc3_distance_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc3rlda_reg_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'geodesic'"
     ]
    }
   ],
   "source": [
    "for i in range(total_locs.shape[0]):\n",
    "    c3_distance_errors.append(geopy.distance.distance(total_locs[i], c3rlda_reg_pred[i]).km)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341.0551765832804"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(c3_distance_errors)/len(c3_distance_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression for ccLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cclda_reg = LinearRegression()\n",
    "cclda_reg.fit(cc_train_ndz, locs)\n",
    "cclda_reg_pred = cclda_reg.predict(cc_ndz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392.66273026113\n"
     ]
    }
   ],
   "source": [
    "cc_distance_errors = []\n",
    "\n",
    "for i in range(total_locs.shape[0]):\n",
    "    cc_distance_errors.append(geopy.distance.distance(total_locs[i], cclda_reg_pred[i]).km)\n",
    "\n",
    "print(sum(cc_distance_errors)/len(cc_distance_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266.9376946555874"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.median(cc_distance_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227.7392804898634"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.median(c3_distance_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234.425078109626"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.median(distance_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

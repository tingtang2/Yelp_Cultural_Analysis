{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc JS distances on og table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nzwcr = np.load(\"./model_persistence/all_eths_less_than_15000_1000_its_25_topics/nzwcr.npy\")\n",
    "\n",
    "nzwc = np.load(\"./model_persistence/all_eths_less_than_15000_1000_its_25_topics/nzwc_ORIGINAL.npy\")\n",
    "\n",
    "breakfast = nzwcr[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marginalize over topics\n",
    "\n",
    "nwc = np.sum(nzwc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_keys = []\n",
    "\n",
    "with open('/Users/tingchen/Desktop/Yelp Project/all_eths_less_than_15000_keys.json', 'r') as infile:\n",
    "    eth_keys = json.load(infile)\n",
    "    \n",
    "eth_keys = np.array(eth_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at breakfast topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_vegas = breakfast[:, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviation of cuisine-region combination for topic from cuisine for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837741150203634"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jensenshannon(japanese_vegas, nzwc[0, :, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7819094271514937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jensenshannon(nzwc[0, :, 1], nzwc[0, :, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hawaiian' 'Filipino' 'Cantonese' 'Cajun/Creole' 'Brazilian' 'Spanish'\n",
      " 'Mexican' 'Tex-Mex' 'Lebanese' 'American (New)' 'Irish' 'French'\n",
      " 'British' 'Indian' 'American (Traditional)' 'German' 'Pakistani'\n",
      " 'Vietnamese' 'Thai' 'Korean' 'Caribbean' 'Italian' 'Greek'\n",
      " 'Middle Eastern' 'Taiwanese' 'Chinese' 'Canadian (New)' 'Japanese']\n"
     ]
    }
   ],
   "source": [
    "deviations_nzwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nzwc.append(jensenshannon(japanese_vegas, nzwc[0, :, i]) - jensenshannon(nzwc[0, :, 1], nzwc[0, :, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nzwc).astype(int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviation of cuisine-region combo from cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788279022634808"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jensenshannon(japanese_vegas, nwc[:, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7670606813019515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jensenshannon(nwc[:, 1], nwc[:, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hawaiian', 'Filipino', 'Tex-Mex', 'Cantonese', 'Brazilian',\n",
       "       'Spanish', 'Cajun/Creole', 'Irish', 'Lebanese', 'German',\n",
       "       'British', 'Mexican', 'French', 'Greek', 'Pakistani', 'Caribbean',\n",
       "       'American (New)', 'American (Traditional)', 'Indian', 'Italian',\n",
       "       'Middle Eastern', 'Taiwanese', 'Thai', 'Vietnamese',\n",
       "       'Canadian (New)', 'Korean', 'Chinese', 'Japanese'], dtype='<U22')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations_nwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nwc.append(jensenshannon(japanese_vegas, nwc[:, i]) - jensenshannon(nwc[:, 1], nwc[:, i]))\n",
    "\n",
    "eth_keys[np.argsort(deviations_nwc).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_toronto = breakfast[:, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canadian (New)' 'Taiwanese' 'British' 'German' 'Caribbean'\n",
      " 'Middle Eastern' 'Lebanese' 'Irish' 'Brazilian' 'Pakistani' 'Greek'\n",
      " 'Spanish' 'Filipino' 'Tex-Mex' 'Indian' 'Cantonese' 'Cajun/Creole'\n",
      " 'French' 'Thai' 'Vietnamese' 'Italian' 'Korean' 'Chinese' 'Mexican'\n",
      " 'American (Traditional)' 'Hawaiian' 'American (New)' 'Japanese']\n"
     ]
    }
   ],
   "source": [
    "deviations_nzwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nzwc.append(jensenshannon(japanese_toronto, nzwc[0, :, i]) - jensenshannon(nzwc[0, :, 1], nzwc[0, :, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nzwc).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canadian (New)' 'Taiwanese' 'Lebanese' 'British' 'Caribbean' 'German'\n",
      " 'Irish' 'Brazilian' 'Pakistani' 'Middle Eastern' 'Filipino' 'Spanish'\n",
      " 'Tex-Mex' 'Greek' 'Indian' 'Cantonese' 'Cajun/Creole' 'French' 'Thai'\n",
      " 'Vietnamese' 'Italian' 'Mexican' 'Korean' 'Hawaiian' 'Chinese'\n",
      " 'American (Traditional)' 'American (New)' 'Japanese']\n"
     ]
    }
   ],
   "source": [
    "deviations_nwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nwc.append(jensenshannon(japanese_toronto, nwc[:, i]) - jensenshannon(nwc[:, 1], nwc[:, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nwc).astype(int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_vegas = breakfast[:, 16, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filipino' 'Hawaiian' 'Brazilian' 'Vietnamese' 'Cantonese' 'Spanish'\n",
      " 'British' 'German' 'Lebanese' 'Irish' 'Cajun/Creole' 'Tex-Mex' 'French'\n",
      " 'Mexican' 'Pakistani' 'Indian' 'Italian' 'American (Traditional)'\n",
      " 'American (New)' 'Caribbean' 'Greek' 'Thai' 'Middle Eastern' 'Taiwanese'\n",
      " 'Chinese' 'Canadian (New)' 'Japanese' 'Korean']\n"
     ]
    }
   ],
   "source": [
    "deviations_nzwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nzwc.append(jensenshannon(korean_vegas, nzwc[0, :, i]) - jensenshannon(nzwc[0, :, 16], nzwc[0, :, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nzwc).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006833748161380715"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations_nzwc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0066911433726082326"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations_nzwc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filipino' 'Cantonese' 'Brazilian' 'Irish' 'Lebanese' 'German' 'Tex-Mex'\n",
      " 'British' 'Spanish' 'Mexican' 'Hawaiian' 'Cajun/Creole' 'French' 'Greek'\n",
      " 'Pakistani' 'Italian' 'Vietnamese' 'Indian' 'Caribbean'\n",
      " 'American (Traditional)' 'Middle Eastern' 'American (New)' 'Thai'\n",
      " 'Taiwanese' 'Canadian (New)' 'Chinese' 'Japanese' 'Korean']\n"
     ]
    }
   ],
   "source": [
    "deviations_nwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nwc.append(jensenshannon(korean_vegas, nwc[:, i]) - jensenshannon(nwc[:, 16], nwc[:, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nwc).astype(int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_phoenix = breakfast[:, 6, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filipino' 'Tex-Mex' 'Hawaiian' 'Cantonese' 'Chinese' 'Brazilian'\n",
      " 'Korean' 'British' 'American (New)' 'Thai' 'Vietnamese' 'Irish'\n",
      " 'Lebanese' 'Japanese' 'French' 'Greek' 'Taiwanese' 'Italian' 'Mexican'\n",
      " 'Pakistani' 'Indian' 'German' 'Middle Eastern' 'American (Traditional)'\n",
      " 'Cajun/Creole' 'Canadian (New)' 'Caribbean' 'Spanish']\n"
     ]
    }
   ],
   "source": [
    "deviations_nzwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nzwc.append(jensenshannon(spanish_phoenix, nzwc[0, :, i]) - jensenshannon(nzwc[0, :, 6], nzwc[0, :, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nzwc).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tex-Mex' 'Irish' 'Cantonese' 'British' 'Lebanese' 'Brazilian' 'German'\n",
      " 'Hawaiian' 'Filipino' 'Cajun/Creole' 'Pakistani' 'Taiwanese' 'Indian'\n",
      " 'Vietnamese' 'Thai' 'Middle Eastern' 'Korean' 'Japanese' 'Mexican'\n",
      " 'Chinese' 'Greek' 'Italian' 'American (Traditional)' 'Canadian (New)'\n",
      " 'Caribbean' 'American (New)' 'French' 'Spanish']\n"
     ]
    }
   ],
   "source": [
    "deviations_nwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nwc.append(jensenshannon(spanish_phoenix, nwc[:, i]) - jensenshannon(nwc[:, 6], nwc[:, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nwc).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_montreal = breakfast[:, 6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canadian (New)' 'Lebanese' 'Taiwanese' 'British' 'Irish' 'German'\n",
      " 'Pakistani' 'Cantonese' 'Middle Eastern' 'Indian' 'Vietnamese' 'Hawaiian'\n",
      " 'Brazilian' 'Cajun/Creole' 'Thai' 'Korean' 'Italian' 'Greek' 'French'\n",
      " 'Japanese' 'Filipino' 'Chinese' 'Caribbean' 'American (Traditional)'\n",
      " 'American (New)' 'Mexican' 'Tex-Mex' 'Spanish']\n"
     ]
    }
   ],
   "source": [
    "deviations_nzwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nzwc.append(jensenshannon(spanish_montreal, nzwc[0, :, i]) - jensenshannon(nzwc[0, :, 6], nzwc[0, :, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nzwc).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lebanese' 'Irish' 'British' 'German' 'Taiwanese' 'Pakistani' 'Cantonese'\n",
      " 'Indian' 'Brazilian' 'Middle Eastern' 'Cajun/Creole' 'Canadian (New)'\n",
      " 'Vietnamese' 'Thai' 'Hawaiian' 'Korean' 'Japanese' 'Italian' 'Greek'\n",
      " 'Caribbean' 'Chinese' 'Filipino' 'American (Traditional)' 'French'\n",
      " 'Tex-Mex' 'Mexican' 'American (New)' 'Spanish']\n"
     ]
    }
   ],
   "source": [
    "deviations_nwc = []\n",
    "\n",
    "for i in range(28):\n",
    "    deviations_nwc.append(jensenshannon(spanish_montreal, nwc[:, i]) - jensenshannon(nwc[:, 6], nwc[:, i]))\n",
    "\n",
    "print(eth_keys[np.argsort(deviations_nwc).astype(int)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

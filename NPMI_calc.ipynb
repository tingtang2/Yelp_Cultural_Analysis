{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import sparse\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_word = np.load(\"./lda/model_persistence/all_eths_less_than_15000_1000_its_25_topics/nzwcr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = np.load(\"./lda/model_persistence/all_eths_less_than_15000_1000_its_25_topics/nzw.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3rLDA_nzwc = np.load(\"/Users/tingchen/Desktop/Yelp_Cultural_Analysis/lda/model_persistence/all_eths_less_than_15000_1000_its_25_topics/nzwc_ORIGINAL.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_assign = np.load(\"./lda/model_persistence/all_eths_less_than_15000_1000_its_25_topics/reg_assign_mat.npy\")\n",
    "indicies_locs_eth = np.load(\"./lda/model_persistence/all_eths_less_than_15000_1000_its_25_topics/indicies_locs_eth.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = sparse.load_npz('/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/X_val.npz')\n",
    "X_test = sparse.load_npz('/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/X_test.npz')\n",
    "cc_val= np.load(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/y_val.npy\")\n",
    "cc_test= np.load(\"/Users/tingchen/Desktop/Yelp Project/data_n_20_removed_all_eths_less_than_15000/y_test.npy\")\n",
    "\n",
    "total_c = np.concatenate((cc_val, cc_test))\n",
    "total_X = sparse.vstack([X_val, X_test])\n",
    "\n",
    "ix = total_X.getnnz(1)>0\n",
    "total_X = total_X[ix]\n",
    "total_c= total_c[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 630854)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_assign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_assign[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3338332,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies_locs_eth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_reg_ind = np.max(reg_assign, axis=1) # number of regions assigned to each cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank top 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c3rLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top10_background = np.argsort(topic_word, axis=1)[:, -20:]\n",
    "\n",
    "# intersect = np.sum(np(X_train[:, top10_background[0][:2]], axis=1))\n",
    "\n",
    "# individuals = np.sum(X_train[:, top10_background[0][:2]], axis=0)\n",
    "\n",
    "# pmi = np.log(10) + np.log(intersect) - np.log(individuals[0, 0]) - np.log(individuals[0, 1])\n",
    "# npmi = -1 * pmi / (np.log(intersect) - math.log(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_npmi(topics):\n",
    "    npmi_means = []\n",
    "    for i, topic in enumerate(topics):\n",
    "        npmi_vals = []\n",
    "        words = topic\n",
    "        print(\"\\rTopic\", i, end=\"\")\n",
    "        for word_i, word1 in enumerate(words):\n",
    "            for word2 in words[word_i+1:]:\n",
    "                col1 = np.array(total_X[:, word1].todense() > 0, dtype=int)\n",
    "                col2 = np.array(total_X[:, word2].todense() > 0, dtype=int)\n",
    "                c1 = col1.sum()\n",
    "                c2 = col2.sum()\n",
    "                c12 = np.sum(col1 * col2)\n",
    "                if c12 == 0:\n",
    "                    npmi = 0.0\n",
    "                else:\n",
    "                    npmi = (np.log10(total_X.shape[0]) + np.log10(c12) - np.log10(c1) - np.log10(c2)) / (np.log10(total_X.shape[0]) - np.log10(c12))\n",
    "                npmi_vals.append(npmi)\n",
    "                #print(str(word1), str(word2))\n",
    "\n",
    "        npmi_means.append(np.mean(npmi_vals))\n",
    "        \n",
    "    print(np.mean(npmi_means))\n",
    "    return np.mean(npmi_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_npmi_culture(topics, cult):\n",
    "    npmi_means = []\n",
    "    for i, topic in enumerate(topics):\n",
    "        npmi_vals = []\n",
    "        words = topic\n",
    "        print(\"\\rTopic\", i, end=\"\")\n",
    "        for word_i, word1 in enumerate(words):\n",
    "            for word2 in words[word_i+1:]:\n",
    "                cult_ind = np.where(total_c == cult)[0]\n",
    "                cult_X = total_X[cult_ind]\n",
    "                \n",
    "                col1 = np.array(cult_X[:, word1].todense() > 0, dtype=int)\n",
    "                col2 = np.array(cult_X[:, word2].todense() > 0, dtype=int)\n",
    "                c1 = col1.sum()\n",
    "                c2 = col2.sum()\n",
    "                c12 = np.sum(col1 * col2)\n",
    "                print(c1, c2, c12, cult_X.shape[0])\n",
    "                if c12 == 0:\n",
    "                    npmi = 0.0\n",
    "                else:\n",
    "                    npmi = (np.log10(cult_X.shape[0]) + np.log10(c12) - np.log10(c1) - np.log10(c2)) / (np.log10(cult_X.shape[0]) - np.log10(c12))\n",
    "                npmi_vals.append(npmi)\n",
    "                print(npmi)\n",
    "\n",
    "        npmi_means.append(np.mean(npmi_vals))\n",
    "    print(\"\\n\")\n",
    "    print(np.mean(npmi_means))\n",
    "    return np.mean(npmi_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_background = np.argsort(topic_word, axis=1)[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.14684326125419578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14684326125419578"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top10_background) # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.16037791742193427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16037791742193427"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top10_background) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3rLDA_nzwc.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 24\n",
      "\n",
      "0.05686325874650356\n",
      "Topic 24\n",
      "\n",
      "0.08802614708585757\n",
      "Topic 24\n",
      "\n",
      "0.05334012141565739\n",
      "Topic 24\n",
      "\n",
      "0.18459221277005544\n",
      "Topic 24\n",
      "\n",
      "0.08692290028675015\n",
      "Topic 24\n",
      "\n",
      "0.07056436710691222\n",
      "Topic 24\n",
      "\n",
      "0.060528292515941\n",
      "Topic 24\n",
      "\n",
      "0.0932889184570643\n",
      "Topic 24\n",
      "\n",
      "0.10582401599915986\n",
      "Topic 24\n",
      "\n",
      "0.08595519618782894\n",
      "Topic 24\n",
      "\n",
      "0.019278823746995844\n",
      "Topic 24\n",
      "\n",
      "0.07182507946082223\n",
      "Topic 24\n",
      "\n",
      "0.09967198453238582\n",
      "Topic 24\n",
      "\n",
      "0.10525047477477084\n",
      "Topic 24\n",
      "\n",
      "0.12960684099845846\n",
      "Topic 24\n",
      "\n",
      "-0.0228215457125284\n",
      "Topic 24\n",
      "\n",
      "0.03686421017290208\n",
      "Topic 24\n",
      "\n",
      "0.07491496459921165\n",
      "Topic 24\n",
      "\n",
      "0.13062221238014307\n",
      "Topic 24\n",
      "\n",
      "0.11622823789053996\n",
      "Topic 24\n",
      "\n",
      "0.08343729229669121\n",
      "Topic 24\n",
      "\n",
      "0.03226444595970498\n",
      "Topic 24\n",
      "\n",
      "0.09856667078263405\n",
      "Topic 24\n",
      "\n",
      "0.006402414239632856\n",
      "Topic 24\n",
      "\n",
      "0.10083582460848194\n",
      "Topic 24\n",
      "\n",
      "0.0715009214342971\n",
      "Topic 24\n",
      "\n",
      "0.11577011157287583\n",
      "Topic 24\n",
      "\n",
      "0.12211657614597496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08136574894484731"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3rlda_culture_npmi = []\n",
    "\n",
    "for c in range(c3rLDA_nzwc.shape[2]):\n",
    "    c3rlda_culture_npmi.append(calculate_npmi_culture(np.argsort(c3rLDA_nzwc[:, :, c], axis=1)[:, -10:], c))\n",
    "    \n",
    "np.mean(c3rlda_culture_npmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.182273803117267\n",
      "Topic 240.2421596163887246\n",
      "Topic 240.3244375789410121\n",
      "Topic 240.3496355349000767\n",
      "Topic 240.18360071302318162\n",
      "Topic 240.23662570678519038\n",
      "Topic 240.23117198600711336\n",
      "Topic 240.258262696746809\n",
      "Topic 240.4436566838337611\n",
      "Topic 240.3696413614198852\n",
      "Topic 240.02346801041637384\n",
      "Topic 240.20513530095738974\n",
      "Topic 240.2801536318144381\n",
      "Topic 240.17799091549840168\n",
      "Topic 240.3636764136274336\n",
      "Topic 24-0.00909439232484937\n",
      "Topic 240.17380731351289658\n",
      "Topic 240.3933446014439055\n",
      "Topic 240.33994634083766123\n",
      "Topic 240.29514050190675456\n",
      "Topic 240.25644693107502803\n",
      "Topic 240.24251709005523975\n",
      "Topic 240.3265189050715355\n",
      "Topic 240.2891807837747459\n",
      "Topic 240.3169721981691476\n",
      "Topic 240.2003537984335443\n",
      "Topic 240.47768746765956804\n",
      "Topic 240.24588996395957646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3rlda_npmi = []\n",
    "\n",
    "for c in range(c3rLDA_nzwc.shape[2]):\n",
    "    c3rlda_culture_npmi.append(calculate_npmi(np.argsort(c3rLDA_nzwc[:, :, c], axis=1)[:, -10:]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2650214806089933"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(c3rlda_culture_npmi[28:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# npmi region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.22400660121620583\n",
      "Topic 240.1372402641063569\n",
      "Topic 240.21791053732718635\n",
      "Topic 240.24819388547674548\n",
      "Topic 240.2027595598187921\n",
      "Topic 240.20192698104515303\n",
      "Topic 240.2533067048177221\n",
      "Topic 240.21476594550272718\n",
      "Topic 240.20829221897272807\n",
      "Topic 240.23827765380798482\n",
      "Topic 240.20222579853773187\n",
      "Topic 240.30096327137279044\n",
      "Topic 240.35866636797346374\n",
      "Topic 240.18317799534566184\n",
      "Topic 240.2046611610637106\n",
      "Topic 240.3245203719563229\n",
      "Topic 240.2505879318632263\n",
      "Topic 240.3054092182746885\n",
      "Topic 240.12344225524874901\n",
      "Topic 240.2880759605763383\n",
      "Topic 240.1455187948696414\n",
      "Topic 240.30986897344666614\n",
      "Topic 240.0919758534836212\n",
      "Topic 240.13274343593567695\n",
      "Topic 240.15882314989194762\n",
      "Topic 240.041235642288965355\n",
      "Topic 240.04645840714240208\n",
      "Topic 240.18755809307996202\n",
      "Topic 240.1592860917598987\n",
      "Topic 240.19133426539057408\n",
      "Topic 240.20125295712298935\n",
      "Topic 240.19903625205937783\n",
      "Topic 240.19724122110338502\n",
      "Topic 240.19113616723168128\n",
      "Topic 240.20311431016708842\n",
      "Topic 240.19058984324280315\n",
      "Topic 240.2352403412489391\n",
      "Topic 240.21226747604904272\n",
      "Topic 240.3142569235690295\n",
      "Topic 240.1918367484304362\n",
      "Topic 240.02812139451120379\n",
      "Topic 240.18407176424103716\n",
      "Topic 240.09060114823954986\n",
      "Topic 240.14028416083681836\n",
      "Topic 240.19584777733803638\n",
      "Topic 240.06030996395777282\n",
      "Topic 240.21405868837311107\n",
      "Topic 240.2543917552697576\n",
      "Topic 240.2223782324935628\n",
      "Topic 240.0632166131456591\n",
      "Topic 240.023539916931671484\n",
      "Topic 240.019085008857177812\n",
      "Topic 240.028387738377367744\n",
      "Topic 240.016762130860496886\n",
      "Topic 240.4010691101272812\n",
      "Topic 240.37134917710000537\n",
      "Topic 240.2954647837811086\n",
      "Topic 240.356013504673268\n",
      "Topic 240.30616269225048054\n",
      "Topic 240.4141689137109759\n",
      "Topic 240.28430532689855287\n",
      "Topic 240.3483141688427486\n",
      "Topic 240.2073388682710104\n",
      "Topic 240.25659404039116723\n",
      "Topic 240.3661633234818846\n",
      "Topic 240.2926180523116673\n",
      "Topic 240.14618956128947255\n",
      "Topic 240.2853428095157359\n",
      "Topic 240.30578629116513983\n",
      "Topic 240.12776860743406798\n",
      "Topic 240.20145694691681248\n",
      "Topic 240.16926044589730402\n",
      "Topic 240.17357169410143158\n",
      "Topic 240.1171489273689433\n",
      "Topic 240.26401803908219684\n",
      "Topic 240.23809106739316285\n",
      "Topic 240.17122657754839246\n",
      "Topic 240.07222750018914023\n",
      "Topic 240.12524951090743489\n",
      "Topic 240.17192356713933182\n",
      "Topic 240.15892900264415494\n",
      "Topic 240.25408553987773724\n",
      "Topic 240.18034034887557468\n",
      "Topic 240.14569533031678245\n",
      "Topic 240.16652258553405563\n",
      "Topic 240.18415895983184835\n",
      "Topic 240.25140337398080453\n",
      "Topic 240.17155031065796666\n",
      "Topic 240.16483134384600975\n",
      "Topic 240.29312459153868015\n",
      "Topic 240.23307538441492773\n",
      "Topic 240.23133024880664782\n",
      "Topic 240.22671574734294037\n",
      "Topic 240.18730368836810524\n",
      "Topic 240.025516855962416426\n",
      "Topic 240.16626441615901869\n",
      "Topic 240.1618480135466834\n",
      "Topic 240.1119885114490342\n",
      "Topic 240.03755733906056628\n",
      "Topic 240.20808486147855287\n",
      "Topic 240.035189080024213004\n",
      "Topic 240.015157129443942303\n",
      "Topic 240.20504449374727213\n",
      "Topic 240.014868561442468873\n",
      "Topic 240.023380174244276887\n",
      "Topic 240.02543563733929173\n",
      "Topic 240.034476797142377405\n",
      "Topic 240.24679095356693806\n",
      "Topic 240.3109991314118747\n",
      "Topic 240.3611900032775637\n",
      "Topic 240.3755301360665157\n",
      "Topic 240.33633204655074633\n",
      "Topic 240.3641924082413835\n",
      "Topic 240.33999621337154307\n",
      "Topic 240.3727179578958612\n",
      "Topic 240.3535516242639099\n",
      "Topic 240.1641294125998109\n",
      "Topic 240.22302419179452282\n",
      "Topic 240.1906246933636392\n",
      "Topic 240.13066608179761793\n",
      "Topic 240.27007304177011177\n",
      "Topic 240.09522156124406447\n",
      "Topic 240.23302356032239896\n",
      "Topic 240.2957282855007933\n",
      "Topic 240.16724356702035073\n",
      "Topic 240.19843233310762032\n",
      "Topic 240.1249654043521008\n",
      "Topic 240.17195247572651595\n",
      "Topic 240.13098978644956166\n",
      "Topic 240.12887746959244234\n",
      "Topic 240.22742019664392862\n",
      "Topic 240.16927888167616942\n",
      "Topic 240.12872223037921865\n",
      "Topic 240.291567602667591\n",
      "Topic 240.35470803699770564\n",
      "Topic 240.26287142614921977\n",
      "Topic 240.05835453671040272\n",
      "Topic 240.19693180785786604\n",
      "Topic 240.3584413192486352\n",
      "Topic 240.33095883793898795\n",
      "Topic 240.3218964103806447\n",
      "Topic 240.29076935312035435\n",
      "Topic 240.2805170700242636\n",
      "Topic 240.2614160839092411\n",
      "Topic 240.2418099745600289\n",
      "Topic 240.26565880160346794\n",
      "Topic 240.30748992855079144\n",
      "Topic 240.2824501975017179\n",
      "Topic 240.15786179409158785\n",
      "Topic 240.02380015083301195\n",
      "Topic 240.01765572407048013\n",
      "Topic 240.24333236327486107\n",
      "Topic 240.2260358058649949\n",
      "Topic 240.23986348076766972\n",
      "Topic 240.24289167456371089\n",
      "Topic 240.24051427786885893\n",
      "Topic 240.16150215194158915\n",
      "Topic 240.1576750502709513\n",
      "Topic 240.19766571233519034\n",
      "Topic 240.24865775744840057\n",
      "Topic 240.14147402185950322\n",
      "Topic 240.18031900727275577\n",
      "Topic 240.1567170879564709\n",
      "Topic 240.26745768935930914\n",
      "Topic 240.22951707231485907\n",
      "Topic 240.24876069652926788\n",
      "Topic 240.16062750521484298\n",
      "Topic 240.02052696688178125\n",
      "Topic 240.16246209630145303\n",
      "Topic 240.01945237198763564\n",
      "Topic 240.33092574535319513\n",
      "Topic 240.25051999443332873\n",
      "Topic 240.036393483416508374\n",
      "Topic 240.022299619041183837\n",
      "Topic 240.05409051303453252\n",
      "Topic 240.07100731396418863\n",
      "Topic 240.0897500858252314\n",
      "Topic 240.09730247844655457\n",
      "Topic 240.06994227947340068\n",
      "Topic 240.3545423506323591\n",
      "Topic 240.22807313499428772\n",
      "Topic 240.017875011448043092\n",
      "Topic 240.2640241626852242\n",
      "Topic 240.17004116842938835\n",
      "Topic 240.4318991708783651\n",
      "Topic 240.021686330598599465\n",
      "Topic 240.25094150000267357\n",
      "Topic 240.26684168134726605\n",
      "Topic 240.2559152513128125\n",
      "Topic 240.2552736470447393\n",
      "Topic 240.26285994096241594\n",
      "Topic 240.31741074510402045\n",
      "Topic 240.26853919167181756\n",
      "Topic 240.26324811491545863\n",
      "Topic 240.1627862642963706\n",
      "Topic 240.2357851982245533\n",
      "Topic 240.16588809767468454\n",
      "Topic 240.25181253913684803\n",
      "Topic 240.04809728080526774\n",
      "Topic 240.09913687477442626\n",
      "Topic 240.1600939431111415\n",
      "Topic 240.11242782210157291\n",
      "Topic 240.17241163664860434\n",
      "Topic 240.4314363667687315\n",
      "Topic 240.39165356345170577\n",
      "Topic 240.10033819219547496\n",
      "Topic 240.43563309365372815\n",
      "Topic 240.035494993925464145\n",
      "Topic 240.08182888306357394\n",
      "Topic 240.2682045350645289\n",
      "Topic 240.03724099205779237\n",
      "Topic 240.02002482714089298\n",
      "Topic 240.27365346343051117\n",
      "Topic 240.04685159287342058\n"
     ]
    }
   ],
   "source": [
    "region_npmis = []\n",
    "\n",
    "for c in range(collection_word.shape[2]):\n",
    "    for r in range(max_reg_ind[c]):\n",
    "        region_npmis.append(calculate_npmi(np.argsort(collection_word[:, :, c, r], axis=1)[:, -10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1979319267745276"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(region_npmis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalized + combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3rLDA_nzw = np.sum(c3rLDA_nzwc, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3rLDA_nzw_total = c3rLDA_nzw + topic_word\n",
    "top10_total = np.argsort(c3rLDA_nzw_total, axis=1)[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.15982803835776038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15982803835776038"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top10_total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 24-0.00865334163403877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00865334163403877"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just marginalized cuisines\n",
    "\n",
    "calculate_npmi(np.argsort(c3rLDA_nzw, axis=1)[:, -10:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6474,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(total_c == 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "model = load('./lda/lda.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.56558789e+03, 1.58458453e+01, 1.46312687e+00, ...,\n",
       "        4.00000000e-02, 4.00000000e-02, 4.00000000e-02],\n",
       "       [8.18525805e+02, 2.33555315e+04, 1.41885869e+01, ...,\n",
       "        4.00000000e-02, 4.00000000e-02, 4.00000000e-02],\n",
       "       [1.26333868e+03, 1.00137837e+03, 2.24027260e+02, ...,\n",
       "        4.00000000e-02, 4.00000000e-02, 4.00000000e-02],\n",
       "       ...,\n",
       "       [1.51671417e+03, 1.18636546e+02, 3.50215289e-01, ...,\n",
       "        4.00000000e-02, 4.00000000e-02, 1.03999998e+00],\n",
       "       [1.05930723e+04, 9.36455970e-01, 5.72863056e-02, ...,\n",
       "        4.00000000e-02, 4.00000000e-02, 4.00000000e-02],\n",
       "       [1.72454466e+03, 1.54000205e+03, 8.44968059e+00, ...,\n",
       "        4.00000000e-02, 4.00000000e-02, 4.00000000e-02]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_words= np.argsort(model.components_, axis=1)[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.15801556524896346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15801556524896346"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top_10_words) # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.19354711797315813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19354711797315813"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top_10_words) # 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ccLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccLDA_nzw = np.load(\"./lda/ccLDA_nzw.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cc = np.argsort(ccLDA_nzw, axis=1)[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.22433079628165384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22433079628165384"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top_cc) # 5 .221 - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.18779829795701353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18779829795701353"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top_cc) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 240.1668965982455381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1668965982455381"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_npmi(top_cc) # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccLDA_nzwc = np.load(\"./lda/ccLDA_nzwc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-15d314e98ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccLDA_nzwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mculture_npmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_npmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mculture_npmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \"\"\"\n\u001b[0;32m-> 1107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "culture_npmi = []\n",
    "\n",
    "for c in range(ccLDA_nzwc.shape[2]):\n",
    "    culture_npmi.append(calculate_npmi(np.argsort(collection_word[:, :, c, r], axis=1)[:, -10:]))\n",
    "    \n",
    "np.mean(culture_npmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 24\n",
      "\n",
      "0.1417480482766072\n",
      "Topic 24\n",
      "\n",
      "0.14374050443130007\n",
      "Topic 24\n",
      "\n",
      "0.16361669282255323\n",
      "Topic 24\n",
      "\n",
      "0.08549038591330332\n",
      "Topic 24\n",
      "\n",
      "0.14885100365020212\n",
      "Topic 24\n",
      "\n",
      "0.18746340309944837\n",
      "Topic 24\n",
      "\n",
      "0.16031614290303098\n",
      "Topic 24\n",
      "\n",
      "0.11424504015835261\n",
      "Topic 24\n",
      "\n",
      "0.10398422260451959\n",
      "Topic 24\n",
      "\n",
      "0.13836743276408198\n",
      "Topic 24\n",
      "\n",
      "0.15536100702724162\n",
      "Topic 24\n",
      "\n",
      "0.1491425699782948\n",
      "Topic 24\n",
      "\n",
      "0.15174319442553785\n",
      "Topic 24\n",
      "\n",
      "0.08089752977740894\n",
      "Topic 24\n",
      "\n",
      "0.15960367511769977\n",
      "Topic 24\n",
      "\n",
      "0.14474223168713535\n",
      "Topic 24\n",
      "\n",
      "0.1830209088656038\n",
      "Topic 24\n",
      "\n",
      "0.057615820540670895\n",
      "Topic 24\n",
      "\n",
      "0.14535879890611164\n",
      "Topic 24\n",
      "\n",
      "0.14830451839472295\n",
      "Topic 24\n",
      "\n",
      "0.15184544227786323\n",
      "Topic 24\n",
      "\n",
      "0.1809745640021049\n",
      "Topic 24\n",
      "\n",
      "0.10206797918413227\n",
      "Topic 24\n",
      "\n",
      "0.07731787674427057\n",
      "Topic 24\n",
      "\n",
      "0.17267616677747955\n",
      "Topic 24\n",
      "\n",
      "0.16182074225278378\n",
      "Topic 24\n",
      "\n",
      "0.11134587759890174\n",
      "Topic 24\n",
      "\n",
      "0.07450638418626117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13557743444170084"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cclda_culture_npmi = []\n",
    "\n",
    "for c in range(ccLDA_nzwc.shape[2]):\n",
    "    cclda_culture_npmi.append(calculate_npmi_culture(np.argsort(ccLDA_nzwc[:, :, c], axis=1)[:, -10:], c))\n",
    "    \n",
    "np.mean(cclda_culture_npmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try palmetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "from palmettopy.palmetto import Palmetto\n",
    "palmetto = Palmetto()\n",
    "\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7b2bf765c1cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minv_lexicon\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mour_lexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtop10_background\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_lexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop10_background\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topic_word' is not defined"
     ]
    }
   ],
   "source": [
    "our_lexicon = Dictionary.load(\"/Users/tingchen/Desktop/Yelp Project/big_lexicon_n_20_removed_all_eths_less_than_15000\")\n",
    "\n",
    "inv_lexicon= {v: k for k, v in our_lexicon.token2id.items()}\n",
    "\n",
    "top10_background = np.argsort(topic_word, axis=1)[:, -10:]\n",
    "\n",
    "words = np.vectorize(inv_lexicon.get)(top10_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmetto_cv = []\n",
    "\n",
    "for i in range(words.shape[0]):\n",
    "    palmetto_cv.append(palmetto.get_coherence(words=list(words[i, :].astype(str)), coherence_type=\"cv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46294999093588024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(palmetto_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca 0.1626923811865238\n",
      "cp -0.07756922590512617\n",
      "npmi -0.011048107168362815\n",
      "umass -5.535219923648257\n"
     ]
    }
   ],
   "source": [
    "coherence_measures = ['ca', 'cp', 'npmi', 'umass']\n",
    "\n",
    "for m in coherence_measures:\n",
    "    topic_coherence = []\n",
    "    \n",
    "    for i in range(words.shape[0]):\n",
    "        topic_coherence.append(palmetto.get_coherence(words=list(words[i, :].astype(str)), coherence_type=m))\n",
    "    \n",
    "    print(m, np.mean(topic_coherence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palmetto for Cuisine topics c3rLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_cuisine = np.argsort(c3rLDA_nzwc, axis=1)[:, -10:, :]\n",
    "\n",
    "words_cuisine = np.vectorize(inv_lexicon.get)(top10_cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [23:50<00:00, 51.10s/it]\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmi -0.06200281257102465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [12:28<00:00, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umass -7.0001380000842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#coherence_measures = ['cv', 'ca', 'cp', 'npmi', 'umass']\n",
    "coherence_measures = ['npmi', 'umass']\n",
    "\n",
    "for m in coherence_measures:\n",
    "    topic_coherence = []\n",
    "    \n",
    "    for c in tqdm(range(c3rLDA_nzwc.shape[2])):\n",
    "        for i in range(words_cuisine.shape[0]):\n",
    "            topic_coherence.append(palmetto.get_coherence(words=list(words_cuisine[i, :, c].astype(str)), coherence_type=m))\n",
    "    \n",
    "    print(m, np.mean(topic_coherence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
